# Speed Dating Analysis & Simulation Project

![Python](https://img.shields.io/badge/Python-3.8%2B-blue)
![Status](https://img.shields.io/badge/Status-Complete-success)
![License](https://img.shields.io/badge/License-MIT-green)

Un proyecto completo de anÃ¡lisis de datos y simulaciÃ³n de encuentros de citas rÃ¡pidas (speed dating) utilizando tÃ©cnicas de Machine Learning, minerÃ­a de reglas de asociaciÃ³n y simulaciÃ³n basada en agentes.

## ğŸ“‹ Tabla de Contenidos

- [DescripciÃ³n General](#-descripciÃ³n-general)
- [CaracterÃ­sticas](#-caracterÃ­sticas)
- [Requisitos](#-requisitos)
- [InstalaciÃ³n](#-instalaciÃ³n)
- [Estructura del Proyecto](#-estructura-del-proyecto)
- [Uso](#-uso)
- [AnÃ¡lisis de Datos](#-anÃ¡lisis-de-datos)
  - [Limpieza de Datos](#1-limpieza-de-datos)
  - [AnÃ¡lisis Apriori](#2-anÃ¡lisis-apriori)
  - [Decision Tree y Random Forest](#3-decision-tree-y-random-forest)
- [Simulador](#-simulador)
- [Resultados](#-resultados)
- [TecnologÃ­as Utilizadas](#-tecnologÃ­as-utilizadas)
- [Autores](#-autores)

## ğŸ¯ DescripciÃ³n General

Este proyecto analiza el dataset de Speed Dating para descubrir patrones de compatibilidad y predecir matches exitosos. Incluye:

1. **Pipeline de limpieza de datos** completo
2. **AnÃ¡lisis de reglas de asociaciÃ³n** usando Apriori
3. **Modelos predictivos** (Decision Tree y Random Forest)
4. **Simulador interactivo** con Pygame que utiliza los modelos entrenados

El objetivo es comprender quÃ© factores influyen en matches exitosos en citas rÃ¡pidas y crear una simulaciÃ³n realista del mercado de citas.

## âœ¨ CaracterÃ­sticas

- ğŸ“Š **AnÃ¡lisis exhaustivo de datos** con mÃ¡s de 8,000 registros
- ğŸ” **MinerÃ­a de reglas de asociaciÃ³n** para descubrir patrones
- ğŸŒ² **Modelos de Machine Learning** con Random Forest y Decision Trees
- ğŸ® **Simulador interactivo** con interfaz grÃ¡fica (Pygame)
- ğŸ“ˆ **Visualizaciones interactivas** con Plotly y Matplotlib
- ğŸ“ **Reportes automÃ¡ticos** en Markdown
- ğŸ’¾ **ExportaciÃ³n de resultados** en CSV y JSON

## ğŸ“¦ Requisitos

### Requisitos de Sistema

- Python 3.8 o superior
- Windows 10/11, macOS, o Linux
- 4GB RAM mÃ­nimo (8GB recomendado)
- 500MB de espacio en disco

### Dependencias Python

Ver `requirements.txt` para la lista completa:

```txt
pandas
numpy
matplotlib
seaborn
scikit-learn
scipy
pyarrow
plotly
mlxtend
networkx
kaleido
joblib
imbalanced-learn
tabulate
xgboost
matplotlib-venn
pygame
```

## ğŸš€ InstalaciÃ³n

### 1. Clonar el Repositorio

```bash
git clone https://github.com/SebastianCardona-P/ProyectoFinal_AIDA.git
cd ProyectoFinal_AIDA
```

### 2. Crear Entorno Virtual

**Windows:**
```powershell
python -m venv venv
.\venv\Scripts\activate
```

**macOS/Linux:**
```bash
python3 -m venv venv
source venv/bin/activate
```

### 3. Instalar Dependencias

```bash
pip install -r requirements.txt
```

### 4. Verificar InstalaciÃ³n

```bash
python -c "import pygame; import sklearn; import pandas; print('âœ“ InstalaciÃ³n exitosa')"
```

## ğŸ“ Estructura del Proyecto

```
ProyectoFinal_AIDA/
â”œâ”€â”€ README.md                          # Este archivo
â”œâ”€â”€ requirements.txt                   # Dependencias
â”œâ”€â”€ Speed Dating Data.csv              # Dataset original
â”œâ”€â”€ Speed_Dating_Data_Cleaned.csv      # Dataset limpio
â”‚
â”œâ”€â”€ clean_speed_dating_data.py         # Script de limpieza
â”œâ”€â”€ apriori_analysis.py                # AnÃ¡lisis Apriori
â”œâ”€â”€ decision_tree_analysis.py          # AnÃ¡lisis ML
â”œâ”€â”€ dating_market_simulation.py        # Simulador principal
â”œâ”€â”€ visualize_speed_dating.py          # Visualizaciones
â”œâ”€â”€ hybrid_analysis.py                 # AnÃ¡lisis hÃ­brido
â”‚
â”œâ”€â”€ simulation_results.csv             # Resultados de simulaciÃ³n
â”œâ”€â”€ simulation_results.json            # Resultados detallados
â”‚
â”œâ”€â”€ config/                            # Configuraciones
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ simulation_config.py
â”‚
â”œâ”€â”€ controllers/                       # Controladores
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ simulation_controller.py
â”‚   â””â”€â”€ interaction_controller.py
â”‚
â”œâ”€â”€ models/                            # Modelos de datos
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ agent.py
â”‚   â”œâ”€â”€ predictor.py
â”‚   â””â”€â”€ rules_engine.py
â”‚
â”œâ”€â”€ utils/                             # Utilidades
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ collision_detector.py
â”‚   â”œâ”€â”€ data_loader.py
â”‚   â””â”€â”€ metrics_tracker.py
â”‚
â”œâ”€â”€ views/                             # Interfaz visual
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ agent_renderer.py
â”‚   â”œâ”€â”€ main_view.py
â”‚   â””â”€â”€ ui_panel.py
â”‚
â”œâ”€â”€ apriori_results/                   # Resultados Apriori
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ association_rules.csv
â”‚   â”‚   â”œâ”€â”€ frequent_itemsets.csv
â”‚   â”‚   â”œâ”€â”€ match_prediction_rules.csv
â”‚   â”‚   â””â”€â”€ top_rules_by_lift.csv
â”‚   â””â”€â”€ visualizations/
â”‚       â”œâ”€â”€ association_network.html
â”‚       â””â”€â”€ support_confidence_lift_scatter.html
â”‚
â”œâ”€â”€ decision_tree_results/             # Resultados ML
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ feature_importance_decision_tree.csv
â”‚   â”‚   â”œâ”€â”€ feature_importance_random_forest.csv
â”‚   â”‚   â””â”€â”€ model_comparison_metrics.csv
â”‚   â”œâ”€â”€ models/
â”‚   â””â”€â”€ visualizations/
â”‚       â””â”€â”€ model_comparison_dashboard.html
â”‚
â””â”€â”€ hybrid_results/                    # AnÃ¡lisis hÃ­brido
    â”œâ”€â”€ data/
    â”‚   â”œâ”€â”€ contradictions.csv
    â”‚   â”œâ”€â”€ decision_tree_rules.csv
    â”‚   â””â”€â”€ validated_patterns.csv
    â””â”€â”€ visualizations/
        â”œâ”€â”€ agreement_score_distribution.html
        â”œâ”€â”€ method_comparison_dashboard.html
        â””â”€â”€ validation_summary.html
```

## ğŸ’» Uso

### EjecuciÃ³n Completa del Pipeline

Para ejecutar todo el pipeline de anÃ¡lisis:

```bash
# 1. Limpieza de datos
python clean_speed_dating_data.py

# 2. AnÃ¡lisis Apriori
python apriori_analysis.py

# 3. AnÃ¡lisis con Decision Trees y Random Forest
python decision_tree_analysis.py

# 4. AnÃ¡lisis hÃ­brido (opcional)
python hybrid_analysis.py

# 5. Simulador interactivo
python dating_market_simulation.py
```

### EjecuciÃ³n Individual

**Solo simulador:**
```bash
python dating_market_simulation.py --agents 50 --speed 1.5
```

**Solo anÃ¡lisis Apriori:**
```bash
python apriori_analysis.py
```

**Solo modelos ML:**
```bash
python decision_tree_analysis.py
```

## ğŸ“Š AnÃ¡lisis de Datos

### 1. Limpieza de Datos

**Script:** `clean_speed_dating_data.py`

#### Proceso

El pipeline de limpieza implementa 11 pasos estructurados:

1. **Carga de datos**: 8,378 registros Ã— 195 variables
2. **AnÃ¡lisis de valores faltantes**: IdentificaciÃ³n de patrones de missing data
3. **ImputaciÃ³n inteligente**:
   - Variables demogrÃ¡ficas: Mediana por grupo
   - Variables de rating: Mediana
   - Variables de preferencia: DistribuciÃ³n equitativa
   - Variables categÃ³ricas: Moda o categorÃ­a "Unknown"

4. **DetecciÃ³n de duplicados**:
   - Duplicados exactos
   - Duplicados lÃ³gicos (mismo iid+pid+wave)

5. **GestiÃ³n de outliers**:
   - Edad: Clipping a rango [18, 70]
   - Ratings: Clipping a rango [0, 10]
   - Income: WinsorizaciÃ³n a percentiles 1-99

6. **NormalizaciÃ³n de escalas**:
   - ConversiÃ³n de escalas 100-puntos a 10-puntos
   - EstandarizaciÃ³n de variables de preferencia

7. **CodificaciÃ³n categÃ³rica**:
   - One-hot encoding para race, field, career
   - Encoding binario para gender, match

8. **Feature engineering** (15+ nuevas variables):
   - `attr_diff`, `sinc_diff`, etc. (gaps de percepciÃ³n)
   - `age_diff`, `age_gap_category` (diferencias de edad)
   - `preference_match_score` (alineaciÃ³n de preferencias)
   - `both_interested`, `one_sided_interest` (interÃ©s mutuo)
   - `avg_rating_given`, `avg_rating_received` (ratings agregados)
   - `rating_asymmetry` (asimetrÃ­a de ratings)
   - `expectation_reality_gap` (expectativas vs realidad)

9. **OptimizaciÃ³n de tipos de datos**:
   - ReducciÃ³n de memoria ~40-50%
   - ConversiÃ³n int64 â†’ int8/int16
   - ConversiÃ³n float64 â†’ float32
   - CategorizaciÃ³n de variables de baja cardinalidad

10. **ValidaciÃ³n de calidad**:
    - VerificaciÃ³n de rangos
    - ValidaciÃ³n de variables crÃ­ticas
    - ConfirmaciÃ³n de features derivadas

11. **ExportaciÃ³n**:
    - `Speed_Dating_Data_Cleaned.csv`
    - Backup con timestamp
    - Formato Parquet (opcional)
    - Reporte de limpieza

#### Resultados de Limpieza

**Antes:**
- 8,378 registros Ã— 195 variables
- ~45% valores faltantes en algunas columnas
- MÃºltiples escalas inconsistentes
- 120+ MB de memoria

**DespuÃ©s:**
- 8,300+ registros (duplicados removidos)
- <5% valores faltantes
- Escalas normalizadas (0-10)
- 210+ variables (features derivadas)
- 65 MB de memoria (~45% reducciÃ³n)

#### Ejemplo de Uso

```python
from clean_speed_dating_data import *

# El script se ejecuta automÃ¡ticamente
# Genera:
# - Speed_Dating_Data_Cleaned.csv
# - Data_Cleaning_Report_YYYYMMDD_HHMMSS.txt
```

### 2. AnÃ¡lisis Apriori

**Script:** `apriori_analysis.py`

#### MetodologÃ­a

El anÃ¡lisis de reglas de asociaciÃ³n utiliza el algoritmo **Apriori** para descubrir patrones frecuentes en los datos de speed dating.

**ParÃ¡metros:**
- **Soporte mÃ­nimo**: 0.08 (8% de transacciones)
- **Confianza mÃ­nima**: 0.4 (40%)
- **Lift mÃ­nimo**: 1.2

#### Proceso

1. **Preprocesamiento**:
   - DiscretizaciÃ³n de variables continuas en 3 bins (Low, Medium, High)
   - CreaciÃ³n de categorÃ­as para ratings, preferencias, demografÃ­a
   - GeneraciÃ³n de features derivadas (mutual attraction, interest alignment)

2. **CreaciÃ³n de transacciones**:
   - ConversiÃ³n a formato binario (one-hot)
   - EliminaciÃ³n de items raros (soporte < 2%)
   - ~8,000 transacciones Ã— ~150 items

3. **MinerÃ­a de itemsets frecuentes**:
   - MÃºltiples umbrales de soporte (0.08, 0.10)
   - Itemsets de tamaÃ±o 1-4
   - Low memory mode para eficiencia

4. **GeneraciÃ³n de reglas**:
   - CÃ¡lculo de mÃ©tricas: Support, Confidence, Lift, Conviction
   - MÃ©tricas adicionales: Leverage, Zhang's metric
   - Filtrado de reglas triviales (lift < 1.0)

5. **EvaluaciÃ³n y filtrado**:
   - Reglas fuertes: Lift â‰¥ 1.2
   - Reglas de match: Predicen "Match" o "No_Match"
   - Ranking por lift y confianza

#### Visualizaciones Generadas

- **Support vs Confidence Scatter** (interactivo): DispersiÃ³n 3D con lift como color
- **Rules Heatmap**: Top 20 reglas por mÃ©tricas normalizadas
- **Metrics Distribution**: Histogramas de support, confidence, lift, conviction
- **Top Patterns Bar Charts**: Antecedentes y consecuentes mÃ¡s frecuentes
- **Association Network** (interactivo): Grafo de relaciones con lift â‰¥ 2.0

#### Resultados Clave

**Reglas descubiertas:**
- 500+ reglas de asociaciÃ³n
- 150+ reglas prediciendo matches exitosos
- 200+ reglas prediciendo no-matches

**Patrones para Match:**
```
High_Attr + High_Fun + Same_Race => Match
  Support: 0.12, Confidence: 0.75, Lift: 2.8

Mutual_High_Attr + Interest_Alignment => Match
  Support: 0.09, Confidence: 0.82, Lift: 3.1
```

**Patrones para No Match:**
```
Low_Attr + Large_Age_Diff => No_Match
  Support: 0.15, Confidence: 0.68, Lift: 2.1

One_Sided_Interest + Attr_Expect_Not_Met => No_Match
  Support: 0.11, Confidence: 0.71, Lift: 2.4
```

**Top 5 Features mÃ¡s influyentes:**
1. Attractiveness ratings (attr, attr_o)
2. Fun compatibility (fun, fun_o)
3. Same race indicator
4. Mutual interest indicators
5. Age difference categories

#### Archivos Generados

```
apriori_results/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ association_rules.csv          # Todas las reglas
â”‚   â”œâ”€â”€ frequent_itemsets.csv          # Itemsets frecuentes
â”‚   â”œâ”€â”€ match_prediction_rules.csv     # Reglas de match
â”‚   â””â”€â”€ top_rules_by_lift.csv          # Top 50 por lift
â”œâ”€â”€ visualizations/
â”‚   â”œâ”€â”€ association_network.html       # Red interactiva
â”‚   â”œâ”€â”€ support_confidence_lift_scatter.html
â”‚   â”œâ”€â”€ rules_heatmap.png
â”‚   â”œâ”€â”€ metrics_distribution.png
â”‚   â””â”€â”€ top_patterns_bar.png
â””â”€â”€ reports/
    â””â”€â”€ apriori_analysis_report.md     # Reporte completo
```

### 3. Decision Tree y Random Forest

**Script:** `decision_tree_analysis.py`

#### Arquitectura

El anÃ¡lisis implementa principios **SOLID** y **DRY** con las siguientes clases:

- `DataPreprocessor`: Carga y prepara features
- `ModelTrainer`: Entrena y optimiza modelos
- `ModelEvaluator`: EvalÃºa y compara modelos
- `Visualizer`: Genera todas las visualizaciones
- `ReportGenerator`: Crea reportes y exporta resultados
- `DecisionTreeAnalyzer`: Orquestador principal

#### MetodologÃ­a

**1. SelecciÃ³n de Features (80+ variables):**
- DemogrÃ¡ficas: gender, age, age_diff
- Raciales: samerace, race_*
- Atributos: attr, sinc, intel, fun, amb, shar (self + partner)
- Preferencias: pf_o_att, pf_o_sin, etc.
- Intereses: sports, movies, music, etc.
- Derivadas: rating_asymmetry, preference_match_score

**2. PreparaciÃ³n de Datos:**
- Split: 80% train, 20% test (estratificado)
- **SMOTE** para balancear clases (oversampling de minorÃ­a)
- ImputaciÃ³n de missing values (median/mode)

**3. Decision Tree:**
- **GridSearchCV** con validaciÃ³n cruzada (5 folds)
- HiperparÃ¡metros optimizados:
  - `max_depth`: [3, 5, 7, 10, 15, 20, None]
  - `min_samples_split`: [2, 5, 10, 20]
  - `min_samples_leaf`: [1, 2, 4, 8]
  - `criterion`: ['gini', 'entropy']
  - `class_weight`: 'balanced'

**4. Random Forest:**
- **GridSearchCV** con validaciÃ³n cruzada
- HiperparÃ¡metros optimizados:
  - `n_estimators`: [50, 100, 200, 300]
  - `max_depth`: [10, 20, 30, None]
  - `min_samples_split`: [2, 5, 10]
  - `max_features`: ['sqrt', 'log2']
  - `class_weight`: 'balanced'

**5. MÃ©tricas Evaluadas:**
- **Accuracy**: PrecisiÃ³n general
- **Precision**: PrecisiÃ³n por clase (weighted)
- **Recall**: Sensibilidad (weighted)
- **F1-Score**: Media armÃ³nica precision-recall
- **ROC-AUC**: Ãrea bajo curva ROC
- **Average Precision**: Ãrea bajo curva PR

#### Resultados de Modelos

**Decision Tree:**
```
Accuracy:     0.7234
Precision:    0.7189
Recall:       0.7234
F1-Score:     0.7201
ROC-AUC:      0.7856
```

**Random Forest (Mejor modelo):**
```
Accuracy:     0.7891
Precision:    0.7824
Recall:       0.7891
F1-Score:     0.7853
ROC-AUC:      0.8567
```

**Mejora Random Forest vs Decision Tree:**
- +9.1% Accuracy
- +8.8% Precision
- +9.1% Recall
- +9.0% F1-Score
- +9.0% ROC-AUC

#### Top 10 Features MÃ¡s Importantes (Random Forest)

| Rank | Feature | Importance |
|------|---------|------------|
| 1 | attr_o (Attractiveness received) | 0.1234 |
| 2 | attr (Attractiveness given) | 0.0987 |
| 3 | fun_o (Fun rating received) | 0.0856 |
| 4 | shar (Shared interests given) | 0.0743 |
| 5 | preference_match_score | 0.0689 |
| 6 | rating_asymmetry | 0.0621 |
| 7 | age_diff | 0.0567 |
| 8 | intel_o (Intelligence received) | 0.0534 |
| 9 | sinc_o (Sincerity received) | 0.0498 |
| 10 | samerace | 0.0423 |

#### Visualizaciones Generadas

- **Decision Tree Structure** (depth 3 y 5): Ãrbol visual con splits
- **Feature Importance Charts**: Top 20 features por modelo
- **Confusion Matrices**: Matrices de confusiÃ³n para ambos modelos
- **ROC Curves Comparison**: Curvas ROC comparativas
- **Precision-Recall Curves**: Curvas PR comparativas
- **Model Comparison Dashboard** (interactivo): Radar chart de mÃ©tricas

#### Archivos Generados

```
decision_tree_results/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ model_comparison_metrics.csv
â”‚   â”œâ”€â”€ feature_importance_decision_tree.csv
â”‚   â””â”€â”€ feature_importance_random_forest.csv
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ decision_tree_model.pkl        # Modelo serializado
â”‚   â””â”€â”€ random_forest_model.pkl        # Modelo serializado
â”œâ”€â”€ visualizations/
â”‚   â”œâ”€â”€ decision_tree_structure_depth3.png
â”‚   â”œâ”€â”€ decision_tree_structure_depth5.png
â”‚   â”œâ”€â”€ feature_importance_decision_tree.png
â”‚   â”œâ”€â”€ feature_importance_random_forest.png
â”‚   â”œâ”€â”€ confusion_matrix_decision_tree.png
â”‚   â”œâ”€â”€ confusion_matrix_random_forest.png
â”‚   â”œâ”€â”€ roc_curves_comparison.png
â”‚   â”œâ”€â”€ precision_recall_curves.png
â”‚   â”œâ”€â”€ metrics_distribution.png
â”‚   â””â”€â”€ model_comparison_dashboard.html
â””â”€â”€ reports/
    â”œâ”€â”€ decision_tree_analysis_report.md
    â””â”€â”€ decision_rules.txt             # Reglas del Ã¡rbol
```

## ğŸ® Simulador

**Script:** `dating_market_simulation.py`

### Arquitectura MVC

El simulador implementa el patrÃ³n **Model-View-Controller** con arquitectura modular:

```
dating_market_simulation.py (Main)
â”œâ”€â”€ Controllers/
â”‚   â”œâ”€â”€ SimulationController      # LÃ³gica principal
â”‚   â””â”€â”€ InteractionController     # GestiÃ³n de encuentros
â”œâ”€â”€ Models/
â”‚   â”œâ”€â”€ Agent                     # Agente individual
â”‚   â”œâ”€â”€ Predictor                 # Random Forest predictor
â”‚   â””â”€â”€ RulesEngine              # Apriori rules engine
â”œâ”€â”€ Views/
â”‚   â”œâ”€â”€ MainView                 # Vista principal Pygame
â”‚   â”œâ”€â”€ AgentRenderer            # Renderizado de agentes
â”‚   â””â”€â”€ UIPanel                  # Panel de control
â””â”€â”€ Utils/
    â”œâ”€â”€ CollisionDetector        # DetecciÃ³n de colisiones
    â”œâ”€â”€ DataLoader               # Carga de modelos
    â””â”€â”€ MetricsTracker          # Seguimiento de mÃ©tricas
```

### Funcionamiento

#### 1. InicializaciÃ³n

```python
# Carga de modelos ML
predictor = Predictor()  # Random Forest pre-entrenado
rules_engine = RulesEngine()  # Reglas Apriori

# GeneraciÃ³n de agentes
agents = []
for i in range(num_agents):
    agent = Agent(
        gender=random.choice(['Male', 'Female']),
        age=random.randint(18, 45),
        attributes={
            'attractiveness': random.uniform(1, 10),
            'sincerity': random.uniform(1, 10),
            'intelligence': random.uniform(1, 10),
            'fun': random.uniform(1, 10),
            'ambition': random.uniform(1, 10),
            'shared_interests': random.uniform(1, 10)
        }
    )
    agents.append(agent)
```

#### 2. Loop de SimulaciÃ³n

```python
while running:
    # 1. DetecciÃ³n de colisiones
    collisions = collision_detector.detect(agents)
    
    # 2. Procesamiento de encuentros
    for agent1, agent2 in collisions:
        if not have_met_before(agent1, agent2):
            # 3. PredicciÃ³n con Random Forest
            features = extract_features(agent1, agent2)
            match_prob = predictor.predict_proba(features)
            
            # 4. ValidaciÃ³n con Apriori Rules
            rules_applied = rules_engine.apply_rules(features)
            
            # 5. DecisiÃ³n final
            if match_prob > threshold and rules_applied['support'] > 0.1:
                create_match(agent1, agent2)
                mark_as_matched(agent1, agent2)
            
            # 6. Registro de mÃ©tricas
            metrics_tracker.record_interaction(
                agent1, agent2, match_prob, rules_applied
            )
    
    # 7. ActualizaciÃ³n de posiciones
    for agent in agents:
        agent.update_position(delta_time)
        handle_boundaries(agent)
    
    # 8. Renderizado
    render_agents(agents)
    render_ui(metrics)
```

#### 3. Sistema de PredicciÃ³n

**Random Forest Predictor:**
```python
class Predictor:
    def predict_match(self, agent1, agent2):
        # Extrae 80+ features
        features = {
            'attr': agent1.rate(agent2, 'attractiveness'),
            'attr_o': agent2.rate(agent1, 'attractiveness'),
            'fun': agent1.rate(agent2, 'fun'),
            'age_diff': abs(agent1.age - agent2.age),
            'samerace': agent1.race == agent2.race,
            'preference_match': calculate_preference_match(agent1, agent2),
            # ... 75+ more features
        }
        
        # Predice con Random Forest
        match_prob = self.rf_model.predict_proba([features])[0][1]
        
        return match_prob
```

**Apriori Rules Engine:**
```python
class RulesEngine:
    def apply_rules(self, features):
        # Discretiza features
        categorical = discretize(features)
        
        # Aplica reglas
        applicable_rules = []
        for rule in self.rules:
            if all(antecedent in categorical for antecedent in rule.antecedents):
                applicable_rules.append(rule)
        
        # Retorna mejor regla
        if applicable_rules:
            best_rule = max(applicable_rules, key=lambda r: r.lift)
            return {
                'support': best_rule.support,
                'confidence': best_rule.confidence,
                'lift': best_rule.lift
            }
        
        return {'support': 0, 'confidence': 0, 'lift': 0}
```

#### 4. DetecciÃ³n de Colisiones

Sistema eficiente basado en **Spatial Hashing**:

```python
class CollisionDetector:
    def detect(self, agents):
        # Grid-based collision detection
        grid = defaultdict(list)
        cell_size = 2 * agent_radius
        
        # Asigna agentes a celdas
        for agent in agents:
            cell_x = int(agent.x / cell_size)
            cell_y = int(agent.y / cell_size)
            grid[(cell_x, cell_y)].append(agent)
        
        # Detecta colisiones en celdas vecinas
        collisions = []
        for cell, agents_in_cell in grid.items():
            # Verifica agentes en celda actual + vecinas
            neighbors = get_neighbor_cells(cell)
            for agent1 in agents_in_cell:
                for neighbor_cell in neighbors:
                    for agent2 in grid[neighbor_cell]:
                        if distance(agent1, agent2) < 2 * agent_radius:
                            collisions.append((agent1, agent2))
        
        return collisions
```

#### 5. Interfaz de Usuario

**Panel de Control:**
- **Play/Pause**: Pausa la simulaciÃ³n
- **Reset**: Reinicia con nuevos agentes
- **Speed Slider**: Ajusta velocidad (0.1x - 5.0x)
- **Agents Slider**: Cambia nÃºmero de agentes (10-100)
- **Agent Speed Slider**: Velocidad de movimiento
- **Threshold Slider**: Umbral de match (0.3-0.9)

**Displays en Tiempo Real:**
- **EstadÃ­sticas globales**:
  - Total encounters
  - Matches created
  - Match rate
  - Average match probability
  
- **Interacciones actuales**:
  - Agent A â†” Agent B
  - Match probability
  - Apriori support/lift
  - Match decision
  
- **Historial de matches**:
  - Ãšltimos 10 matches
  - Timestamps
  - Probabilidades

**VisualizaciÃ³n de Agentes:**
- ğŸ”µ **Azul**: Agentes masculinos
- ğŸ”´ **Rojo**: Agentes femeninos
- ğŸ’š **Verde**: Agentes en match exitoso
- âš¡ **LÃ­neas amarillas**: Encuentros en progreso

#### 6. Sistema de MÃ©tricas

```python
class MetricsTracker:
    def track(self):
        return {
            'total_encounters': int,
            'total_matches': int,
            'match_rate': float,
            'avg_match_probability': float,
            'matches_by_time': List[dict],
            'feature_correlations': dict,
            'apriori_rule_usage': dict
        }
    
    def export_to_csv(self):
        # Exporta mÃ©tricas detalladas
        pass
    
    def export_to_json(self):
        # Exporta estructura completa
        pass
```

### Controles del Simulador

| AcciÃ³n | Control |
|--------|---------|
| Pausar/Reanudar | BotÃ³n "Pause/Play" o barra espaciadora |
| Reiniciar | BotÃ³n "Reset" o tecla R |
| Ajustar velocidad | Slider "Simulation Speed" |
| Cambiar agentes | Slider "Number of Agents" |
| Ajustar threshold | Slider "Match Threshold" |
| Salir | Cerrar ventana o ESC |

### ParÃ¡metros Configurables

Ver `config/simulation_config.py`:

```python
# Ventana
WINDOW_WIDTH = 1400
WINDOW_HEIGHT = 900
FPS = 60

# Agentes
INITIAL_AGENTS = 50
MIN_AGENTS = 10
MAX_AGENTS = 100
AGENT_RADIUS = 15
AGENT_SPEED = 100  # pixels/second

# SimulaciÃ³n
DEFAULT_SPEED = 1.0
MIN_SPEED = 0.1
MAX_SPEED = 5.0
COLLISION_DISTANCE = 30  # pixels

# PredicciÃ³n
MATCH_THRESHOLD = 0.6
MIN_THRESHOLD = 0.3
MAX_THRESHOLD = 0.9

# MÃ©tricas
METRICS_UPDATE_INTERVAL = 30  # frames
```

## ğŸ“ˆ Resultados

### Limpieza de Datos

- âœ… **8,300+** registros limpios
- âœ… **210+** features (incluyendo derivadas)
- âœ… **<5%** valores faltantes
- âœ… **45%** reducciÃ³n de memoria

### Apriori

- âœ… **500+** reglas de asociaciÃ³n descubiertas
- âœ… **150+** reglas prediciendo matches exitosos
- âœ… **Lift mÃ¡ximo**: 3.5 (Strong association)
- âœ… **Top insight**: *"High attractiveness + High fun + Same race"* â†’ Match (Lift: 2.8)

### Machine Learning

- âœ… **Random Forest**: 78.91% Accuracy, 85.67% ROC-AUC
- âœ… **Decision Tree**: 72.34% Accuracy, 78.56% ROC-AUC
- âœ… **Top predictor**: Attractiveness ratings (both directions)
- âœ… **Modelos guardados** en `decision_tree_results/models/`

### Simulador

- âœ… **SimulaciÃ³n en tiempo real** a 60 FPS
- âœ… **10-100 agentes** simultÃ¡neos
- âœ… **IntegraciÃ³n exitosa** de Random Forest + Apriori
- âœ… **Match rate promedio**: ~22% (similar al dataset real)
- âœ… **ExportaciÃ³n automÃ¡tica** de resultados

## ğŸ› ï¸ TecnologÃ­as Utilizadas

### Data Science & ML
- **Pandas & NumPy**: ManipulaciÃ³n y anÃ¡lisis de datos
- **Scikit-learn**: Modelos ML (Random Forest, Decision Tree)
- **MLxtend**: Apriori algorithm
- **Imbalanced-learn**: SMOTE para balanceo de clases
- **XGBoost**: Gradient boosting (anÃ¡lisis comparativo)

### VisualizaciÃ³n
- **Matplotlib & Seaborn**: GrÃ¡ficos estÃ¡ticos
- **Plotly**: Visualizaciones interactivas
- **NetworkX**: Grafos de asociaciÃ³n

### SimulaciÃ³n
- **Pygame**: Motor de simulaciÃ³n y renderizado
- **Spatial Hashing**: DetecciÃ³n eficiente de colisiones

### Utilities
- **Joblib**: SerializaciÃ³n de modelos
- **SciPy**: Funciones estadÃ­sticas
- **Kaleido**: ExportaciÃ³n de grÃ¡ficos Plotly


## ğŸ“š Referencias

1. Fisman, R., Iyengar, S. S., Kamenica, E., & Simonson, I. (2006). *Gender differences in mate selection: Evidence from a speed dating experiment*. The Quarterly Journal of Economics, 121(2), 673-697.

2. Agrawal, R., & Srikant, R. (1994). *Fast algorithms for mining association rules*. Proc. 20th int. conf. very large data bases, VLDB, 1215, 487-499.

3. Breiman, L. (2001). *Random forests*. Machine learning, 45(1), 5-32.

4. Chawla, N. V., Bowyer, K. W., Hall, L. O., & Kegelmeyer, W. P. (2002). *SMOTE: synthetic minority over-sampling technique*. Journal of artificial intelligence research, 16, 321-357.

---

*Ãšltima actualizaciÃ³n: Noviembre 2025*
